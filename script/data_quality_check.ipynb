{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e9e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bases carregadas com sucesso!\n",
      "Fato: 300 registros | Dim_SB: 11 | Dim_Trem: 7\n",
      "\n",
      "üìä Completude (% de valores nulos por coluna):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_operacao                 0.0\n",
       "data_operacao               0.0\n",
       "id_trem                     0.0\n",
       "id_sb                       0.0\n",
       "tempo_transit             100.0\n",
       "tempo_parado              100.0\n",
       "capacidade_bruta            0.0\n",
       "carga_transportada          0.0\n",
       "km_percorrido               0.0\n",
       "anomalias                   0.0\n",
       "saturacao                 100.0\n",
       "eficiencia_operacional      0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Registros com satura√ß√£o > 150%: 0\n",
      "‚ö†Ô∏è Registros com tempos inv√°lidos: 0\n",
      "\n",
      "üìÖ Per√≠odo de opera√ß√£o: 2024-01-01 a 2024-04-29\n",
      "\n",
      "üîÅ Registros duplicados (id_trem + id_sb + data_operacao): 1\n",
      "\n",
      "üîó Registros com SB inexistente: 0\n",
      "üîó Registros com Trem inexistente: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completude M√©dia (%)</th>\n",
       "      <th>Satura√ß√µes Inv√°lidas (%)</th>\n",
       "      <th>Tempos Inv√°lidos (%)</th>\n",
       "      <th>Duplicados (%)</th>\n",
       "      <th>Integridade SB (%)</th>\n",
       "      <th>Integridade Trem (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Qualidade Geral</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Completude M√©dia (%)  Satura√ß√µes Inv√°lidas (%)  \\\n",
       "Qualidade Geral                  75.0                       0.0   \n",
       "\n",
       "                 Tempos Inv√°lidos (%)  Duplicados (%)  Integridade SB (%)  \\\n",
       "Qualidade Geral                   0.0            0.33               100.0   \n",
       "\n",
       "                 Integridade Trem (%)  \n",
       "Qualidade Geral                 100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ An√°lise de Data Quality conclu√≠da!\n",
      "Os resultados podem ser adicionados ao README.md para documentar a consist√™ncia das bases.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# üßπ Data Quality Check ‚Äì Dashboard de Performance Log√≠stica\n",
    "# Autor: Krisley Gregory\n",
    "# Descri√ß√£o: Avalia a qualidade dos dados simulados utilizados\n",
    "# no painel de Performance Log√≠stica (Power BI)\n",
    "# =====================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# 1. Carregamento das bases\n",
    "# -------------------------\n",
    "fato = pd.read_csv(r'C:\\Users\\kriss\\Documents\\2. Estudos\\Estudos\\An√°lise de Dados\\data\\data_analytics\\fato_operacao_logistica.csv')\n",
    "dim_trem = pd.read_csv(r'C:\\Users\\kriss\\Documents\\2. Estudos\\Estudos\\An√°lise de Dados\\data\\data_analytics\\dim_trem.csv')\n",
    "dim_sb = pd.read_csv(r'C:\\Users\\kriss\\Documents\\2. Estudos\\Estudos\\An√°lise de Dados\\data\\data_analytics\\dim_sb.csv')\n",
    "\n",
    "print(\"‚úÖ Bases carregadas com sucesso!\")\n",
    "print(f\"Fato: {fato.shape[0]} registros | Dim_SB: {dim_sb.shape[0]} | Dim_Trem: {dim_trem.shape[0]}\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. Convers√£o de tipos\n",
    "# -------------------------\n",
    "# Garante que colunas num√©ricas sejam realmente num√©ricas\n",
    "for col in ['saturacao', 'tempo_transit', 'tempo_parado']:\n",
    "    if col in fato.columns:\n",
    "        fato[col] = pd.to_numeric(fato[col], errors='coerce')\n",
    "\n",
    "# -------------------------\n",
    "# 3. Completude\n",
    "# -------------------------\n",
    "completude = fato.isnull().mean().round(4) * 100\n",
    "print(\"üìä Completude (% de valores nulos por coluna):\")\n",
    "display(completude)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Consist√™ncia de faixas e tipos\n",
    "# -------------------------\n",
    "erros_saturacao = fato.loc[fato['saturacao'] > 150]\n",
    "erros_tempo = fato.loc[(fato['tempo_transit'] <= 0) | (fato['tempo_parado'] < 0)]\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Registros com satura√ß√£o > 150%: {len(erros_saturacao)}\")\n",
    "print(f\"‚ö†Ô∏è Registros com tempos inv√°lidos: {len(erros_tempo)}\")\n",
    "\n",
    "# -------------------------\n",
    "# 5. Validade de datas\n",
    "# -------------------------\n",
    "if 'data_operacao' in fato.columns:\n",
    "    fato['data_operacao'] = pd.to_datetime(fato['data_operacao'], errors='coerce')\n",
    "    min_data, max_data = fato['data_operacao'].min(), fato['data_operacao'].max()\n",
    "    if pd.notnull(min_data) and pd.notnull(max_data):\n",
    "        print(f\"\\nüìÖ Per√≠odo de opera√ß√£o: {min_data.date()} a {max_data.date()}\")\n",
    "    else:\n",
    "        print(\"\\nüìÖ Datas inv√°lidas ou ausentes na base de fato.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Coluna 'data_operacao' n√£o encontrada na base de fato.\")\n",
    "\n",
    "# -------------------------\n",
    "# 6. Unicidade\n",
    "# -------------------------\n",
    "chaves = ['id_trem', 'id_sb', 'data_operacao']\n",
    "chaves_presentes = [c for c in chaves if c in fato.columns]\n",
    "if chaves_presentes:\n",
    "    duplicados = fato.duplicated(subset=chaves_presentes).sum()\n",
    "    print(f\"\\nüîÅ Registros duplicados ({' + '.join(chaves_presentes)}): {duplicados}\")\n",
    "else:\n",
    "    duplicados = np.nan\n",
    "    print(\"\\n‚ö†Ô∏è Colunas de chave n√£o encontradas para verifica√ß√£o de duplicidade.\")\n",
    "\n",
    "# -------------------------\n",
    "# 7. Integridade referencial\n",
    "# -------------------------\n",
    "sb_invalidos = fato[~fato['id_sb'].isin(dim_sb['id_sb'])] if 'id_sb' in fato.columns and 'id_sb' in dim_sb.columns else pd.DataFrame()\n",
    "trem_invalidos = fato[~fato['id_trem'].isin(dim_trem['id_trem'])] if 'id_trem' in fato.columns and 'id_trem' in dim_trem.columns else pd.DataFrame()\n",
    "\n",
    "print(f\"\\nüîó Registros com SB inexistente: {len(sb_invalidos)}\")\n",
    "print(f\"üîó Registros com Trem inexistente: {len(trem_invalidos)}\")\n",
    "\n",
    "# -------------------------\n",
    "# 8. Sum√°rio de Qualidade\n",
    "# -------------------------\n",
    "total_registros = len(fato)\n",
    "metricas = {\n",
    "    'Completude M√©dia (%)': round(100 - completude.mean(), 2),\n",
    "    'Satura√ß√µes Inv√°lidas (%)': round((len(erros_saturacao) / total_registros) * 100, 2),\n",
    "    'Tempos Inv√°lidos (%)': round((len(erros_tempo) / total_registros) * 100, 2),\n",
    "    'Duplicados (%)': round((duplicados / total_registros) * 100, 2) if not np.isnan(duplicados) else np.nan,\n",
    "    'Integridade SB (%)': round(100 - (len(sb_invalidos) / total_registros) * 100, 2),\n",
    "    'Integridade Trem (%)': round(100 - (len(trem_invalidos) / total_registros) * 100, 2)\n",
    "}\n",
    "\n",
    "df_quality = pd.DataFrame(metricas, index=['Qualidade Geral'])\n",
    "display(df_quality)\n",
    "\n",
    "# -------------------------\n",
    "# 9. Conclus√£o\n",
    "# -------------------------\n",
    "print(\"\\n‚úÖ An√°lise de Data Quality conclu√≠da!\")\n",
    "print(\"Os resultados podem ser adicionados ao README.md para documentar a consist√™ncia das bases.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
